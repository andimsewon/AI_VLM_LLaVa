# %%
import torch
from transformers import (
    AutoTokenizer,
    AutoProcessor,
    TrainingArguments,
    LlavaForConditionalGeneration,
    BitsAndBytesConfig,
)
from trl import SFTTrainer
from peft import LoraConfig

# 모델 ID 설정
model_id = "llava-hf/llava-1.5-7b-hf"  # 사용하려는 LLaVa 모델 ID

# %%
# 양자화 설정을 통해 모델을 메모리 효율적으로 로드하기 위한 BitsAndBytesConfig 설정
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,  # 모델을 4비트로 양자화하여 메모리 사용량 절감
)

# LLaVa 모델 로드 (양자화된 형태로 로드)
model = LlavaForConditionalGeneration.from_pretrained(
    model_id, quantization_config=quantization_config, torch_dtype=torch.float16
)

# %%
# LLaVa 채팅 템플릿 정의
# 사용자와 AI 간의 대화 형식을 정의한 템플릿
LLAVA_CHAT_TEMPLATE = """
A chat between a curious user and an artificial intelligence assistant. 
The assistant gives helpful, detailed, and polite answers to the user's questions. 
{% for message in messages %}
  {% if message['role'] == 'user' %}
    USER: 
  {% else %}
    ASSISTANT: 
  {% endif %}
  {% for item in message['content'] %}
    {% if item['type'] == 'text' %}
      {{ item['text'] }}
    {% elif item['type'] == 'image' %}
      <image>
    {% endif %}
  {% endfor %}
  {% if message['role'] == 'user' %}
  {% else %}
    {{eos_token}}
  {% endif %}
{% endfor %}
"""

# 토크나이저 및 프로세서 로드
# 토크나이저와 프로세서에 채팅 템플릿을 적용하여 사용자 정의 대화 형식을 지원

# 모델 ID로부터 토크나이저 로드
tokenizer = AutoTokenizer.from_pretrained(model_id)
# 템플릿 적용
tokenizer.chat_template = LLAVA_CHAT_TEMPLATE
# 모델 ID로부터 프로세서 로드
processor = AutoProcessor.from_pretrained(model_id)

# %%
# 데이터셋 구축
import os
import pandas as pd
from PIL import Image
from datasets import Dataset

# 경로 정의
message_file_path = "AI_contents/messages.txt"  # 대화 내용 파일 경로
image_folder_path = "AI_contents/frames"  # 이미지 파일 폴더 경로
csv_file_path = "AI_contents/labels.csv"  # CSV 메타데이터 파일 경로

# 데이터 로드
with open(message_file_path, "r") as f:
    messages = f.read()  # 대화 메시지 파일 읽기

labels_df = pd.read_csv(csv_file_path)  # CSV 파일을 pandas 데이터프레임으로 로드

# Dataset 준비를 위한 데이터 처리
# CSV 파일의 각 행을 순회하면서 데이터 준비
data = []

for idx, row in labels_df.iterrows():
    image_id = row["id"]  # 이미지 ID 추출
    count = row["count"]  # 사람 수 정보 추출

    # 이미지 파일 경로 가져오기
    image_file_name = f"seq_{image_id:06d}.jpg"  # 이미지 파일명 구성 (예: seq_000001.jpg)
    image_path = os.path.join(image_folder_path, image_file_name)

    # 대화 메시지 템플릿 생성
    # 사용자와 AI 어시스턴트 간의 Q&A 형식으로 템플릿 구성
    message_template = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "How many people are in this photo?"},
                {"type": "image"},  # 이미지가 포함된 질문
            ],
        },
        {
            "role": "assistant",
            "content": [
                {
                    "type": "text",
                    "text": f"There are about {count} people in the photo.",  # 사람 수에 대한 대답
                }
            ],
        },
    ]

    # 이미지 경로와 메시지 템플릿을 데이터셋에 추가
    data.append({"images": image_path, "messages": message_template})

# HuggingFace Dataset으로 변환
# 데이터셋을 Hugging Face의 Dataset 형식으로 변환하여 처리에 용이하게 함
hf_dataset = Dataset.from_dict(
    {
        "images": [item["images"] for item in data],
        "messages": [item["messages"] for item in data],
    }
)

# 학습/평가 데이터셋 나누기 (예: 80/20 split)
split_dataset = hf_dataset.train_test_split(test_size=0.2)  # 학습 데이터와 평가 데이터로 분할

# 데이터셋 저장
split_dataset.save_to_disk("processed_dataset")  # 처리된 데이터셋을 디스크에 저장

# %%
from datasets import load_from_disk

# 저장된 데이터셋 불러오기
dataset = load_from_disk("processed_dataset")
print(dataset["train"][0])  # 학습 데이터 샘플 확인
train_dataset = dataset["train"]
eval_dataset = dataset["test"]

print("eval_dataset : ", eval_dataset[0])  # 평가 데이터 샘플 확인

# %%
# 데이터 Collator 정의
# 배치를 구성할 때 텍스트와 이미지를 함께 처리

def collate_fn(examples):
    # 텍스트와 이미지 가져오고 템플릿 적용
    texts = [
        processor.apply_chat_template(example["messages"], tokenize=False)
        for example in examples
    ]
    images = [Image.open(example["images"]).convert("RGB") for example in examples]

    # 텍스트와 이미지를 토큰화 및 처리
    batch = processor(texts, images, return_tensors="pt", padding=True)

    # 라벨 설정 (패딩 토큰은 손실 계산에서 제외)
    labels = batch["input_ids"].clone()
    labels[labels == processor.tokenizer.pad_token_id] = -100
    batch["labels"] = labels

    return batch

# 학습 설정 정의
training_args = TrainingArguments(
    output_dir="llava-1.5-7b-hf-ft-mix-vsft",  # 학습 결과 저장 경로
    report_to="tensorboard",  # Tensorboard를 통한 시각화 보고 설정
    evaluation_strategy="epoch",  # 매 에폭마다 평가 수행
    logging_steps=100,  # 100 스텝마다 로그 기록
    learning_rate=1.4e-5,  # 학습률 설정
    per_device_train_batch_size=8,  # 장치당 배치 크기 설정
    gradient_accumulation_steps=1,  # 그래디언트 누적 단계 수
    num_train_epochs=1,  # 학습 에폭 수
    push_to_hub=True,  # 학습 후 Hugging Face Hub에 푸시
    gradient_checkpointing=True,  # 그래디언트 체크포인팅 활성화 (메모리 절약)
    remove_unused_columns=False,  # 사용하지 않는 컬럼 제거 안 함
    fp16=True,  # 16-bit 부동소수점 사용 (메모리 최적화)
    bf16=False,  # bf16 비활성화
)

# LoRA 설정 정의 (Low-Rank Adaptation)
lora_config = LoraConfig(
    r=64,  # 랭크 설정
    lora_alpha=16,  # LoRA 알파값 설정
    target_modules="all-linear"  # 모든 선형 모듈을 타겟으로 설정
)

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

# 평가 지표 계산 함수 정의
def compute_metrics(pred):
    labels = pred.label_ids  # 정답 라벨
    preds = pred.predictions.argmax(-1)  # 모델 예측값 (가장 높은 확률을 가진 값 선택)
    
    # precision, recall, f1 점수 계산
    precision, recall, f1, _ = precision_recall_fscore_support(
        labels, preds, average="binary"
    )
    
    # 정확도 계산
    acc = accuracy_score(labels, preds)
    
    return {
        "accuracy": acc,  # 정확도
        "f1": f1,  # F1 점수
        "precision": precision,  # 정밀도
        "recall": recall  # 재현율
    }

# SFTTrainer를 사용한 모델 학습 설정
trainer = SFTTrainer(
    model=model,  # 미세 조정할 모델
    args=training_args,  # 학습 설정
    train_dataset=train_dataset,  # 학습 데이터셋
    eval_dataset=eval_dataset,  # 평가 데이터셋
    peft_config=lora_config,  # LoRA 설정
    compute_metrics=compute_metrics,  # 평가 지표 함수 설정
    dataset_text_field="text",  # 필요한 더미 필드 (사용하지 않더라도 필수 값)
    data_collator=collate_fn,  # 데이터 Collator 함수 설정
    processing_class=processor.tokenizer,  # 토크나이

