import torch
from transformers import (
    AutoTokenizer,
    AutoProcessor,
    TrainingArguments,
    LlavaForConditionalGeneration,
    BitsAndBytesConfig,
)
from trl import SFTTrainer
from peft import LoraConfig

# 모델 ID 설정
model_id = "llava-hf/llava-1.5-7b-hf"  # 사용하려는 LLaVa 모델 ID

# 양자화 설정을 통해 모델을 메모리 효율적으로 로드하기 위한 BitsAndBytesConfig 설정
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,  # 모델을 4비트로 양자화하여 메모리 사용량 절감
)

# LLaVa 모델 로드 (양자화된 형태로 로드)
model = LlavaForConditionalGeneration.from_pretrained(
    model_id, quantization_config=quantization_config, torch_dtype=torch.float16
)

# LLaVa 채팅 템플릿 정의
LLAVA_CHAT_TEMPLATE = """
A chat between a curious user and an artificial intelligence assistant. 
The assistant gives helpful, detailed, and polite answers to the user's questions. 
{% for message in messages %}
  {% if message['role'] == 'user' %}
    USER: 
  {% else %}
    ASSISTANT: 
  {% endif %}
  {% for item in message['content'] %}
    {% if item['type'] == 'text' %}
      {{ item['text'] }}
    {% elif item['type'] == 'image' %}
      <image>
    {% endif %}
  {% endfor %}
  {% if message['role'] == 'user' %}
  {% else %}
    {{eos_token}}
  {% endif %}
{% endfor %}
"""

# 토크나이저 및 프로세서 로드
tokenizer = AutoTokenizer.from_pretrained(model_id)
tokenizer.chat_template = LLAVA_CHAT_TEMPLATE
processor = AutoProcessor.from_pretrained(model_id)

# 데이터셋 구축
import os
import pandas as pd
from PIL import Image
from datasets import Dataset

# 경로 정의
message_file_path = "AI_contents/messages.txt"
image_folder_path = "AI_contents/frames"
csv_file_path = "AI_contents/labels.csv"

# 데이터 로드
with open(message_file_path, "r") as f:
    messages = f.read()

labels_df = pd.read_csv(csv_file_path)

# Dataset 준비를 위한 데이터 처리
data = []

for idx, row in labels_df.iterrows():
    image_id = row["id"]
    count = row["count"]

    image_file_name = f"seq_{image_id:06d}.jpg"
    image_path = os.path.join(image_folder_path, image_file_name)

    message_template = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "How many people are in this photo?"},
                {"type": "image"},
            ],
        },
        {
            "role": "assistant",
            "content": [
                {
                    "type": "text",
                    "text": f"There are about {count} people in the photo.",
                }
            ],
        },
    ]

    data.append({"images": image_path, "messages": message_template})

# HuggingFace Dataset으로 변환
hf_dataset = Dataset.from_dict(
    {
        "images": [item["images"] for item in data],
        "messages": [item["messages"] for item in data],
    }
)

# 학습/평가 데이터셋 나누기
split_dataset = hf_dataset.train_test_split(test_size=0.2)

# 데이터셋 저장
split_dataset.save_to_disk("processed_dataset")

# 저장된 데이터셋 불러오기
from datasets import load_from_disk

dataset = load_from_disk("processed_dataset")
train_dataset = dataset["train"]
eval_dataset = dataset["test"]

# 데이터 Collator 정의
def collate_fn(examples):
    texts = [
        processor.apply_chat_template(example["messages"], tokenize=False)
        for example in examples
    ]
    images = [Image.open(example["images"]).convert("RGB") for example in examples]

    batch = processor(texts, images, return_tensors="pt", padding=True)

    labels = batch["input_ids"].clone()
    labels[labels == processor.tokenizer.pad_token_id] = -100
    batch["labels"] = labels

    return batch

# 학습 설정 정의
training_args = TrainingArguments(
    output_dir="llava-1.5-7b-hf-ft-mix-vsft",
    report_to="tensorboard",
    evaluation_strategy="epoch",
    logging_steps=100,
    learning_rate=1.4e-5,
    per_device_train_batch_size=8,
    gradient_accumulation_steps=1,
    num_train_epochs=1,
    push_to_hub=True,
    gradient_checkpointing=True,
    remove_unused_columns=False,
    fp16=True,
    bf16=False,
)

# LoRA 설정 정의
lora_config = LoraConfig(
    r=64,
    lora_alpha=16,
    target_modules="all-linear"
)

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    
    precision, recall, f1, _ = precision_recall_fscore_support(
        labels, preds, average="binary"
    )
    
    acc = accuracy_score(labels, preds)
    
    return {
        "accuracy": acc,
        "f1": f1,
        "precision": precision,
        "recall": recall
    }

# SFTTrainer를 사용한 모델 학습 설정
trainer = SFTTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    peft_config=lora_config,
    compute_metrics=compute_metrics,
    dataset_text_field="text",
    data_collator=collate_fn,
    processing_class=processor.tokenizer,
)
